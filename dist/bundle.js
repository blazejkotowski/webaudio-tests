/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/index.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./node_modules/msr/MediaStreamRecorder.js":
/*!*************************************************!*\
  !*** ./node_modules/msr/MediaStreamRecorder.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;// Last time updated: 2016-07-03 8:51:35 AM UTC\n\n// links:\n// Open-Sourced: https://github.com/streamproc/MediaStreamRecorder\n// https://cdn.WebRTC-Experiment.com/MediaStreamRecorder.js\n// https://www.WebRTC-Experiment.com/MediaStreamRecorder.js\n// npm install msr\n\n//------------------------------------\n\n// Browsers Support::\n// Chrome (all versions) [ audio/video separately ]\n// Firefox ( >= 29 ) [ audio/video in single webm/mp4 container or only audio in ogg ]\n// Opera (all versions) [ same as chrome ]\n// Android (Chrome) [ only video ]\n// Android (Opera) [ only video ]\n// Android (Firefox) [ only video ]\n// Microsoft Edge (Only Audio & Gif)\n\n//------------------------------------\n// Muaz Khan     - www.MuazKhan.com\n// MIT License   - www.WebRTC-Experiment.com/licence\n//------------------------------------\n\n// ______________________\n// MediaStreamRecorder.js\n\nfunction MediaStreamRecorder(mediaStream) {\n    if (!mediaStream) {\n        throw 'MediaStream is mandatory.';\n    }\n\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        var Recorder;\n\n        if (typeof MediaRecorder !== 'undefined') {\n            Recorder = MediaRecorderWrapper;\n        } else if (IsChrome || IsOpera || IsEdge) {\n            if (this.mimeType.indexOf('video') !== -1) {\n                Recorder = WhammyRecorder;\n            } else if (this.mimeType.indexOf('audio') !== -1) {\n                Recorder = StereoAudioRecorder;\n            }\n        }\n\n        // video recorder (in GIF format)\n        if (this.mimeType === 'image/gif') {\n            Recorder = GifRecorder;\n        }\n\n        // audio/wav is supported only via StereoAudioRecorder\n        // audio/pcm (int16) is supported only via StereoAudioRecorder\n        if (this.mimeType === 'audio/wav' || this.mimeType === 'audio/pcm') {\n            Recorder = StereoAudioRecorder;\n        }\n\n        // allows forcing StereoAudioRecorder.js on Edge/Firefox\n        if (this.recorderType) {\n            Recorder = this.recorderType;\n        }\n\n        mediaRecorder = new Recorder(mediaStream);\n        mediaRecorder.blobs = [];\n\n        var self = this;\n        mediaRecorder.ondataavailable = function(data) {\n            mediaRecorder.blobs.push(data);\n            self.ondataavailable(data);\n        };\n        mediaRecorder.onstop = this.onstop;\n        mediaRecorder.onStartedDrawingNonBlankFrames = this.onStartedDrawingNonBlankFrames;\n\n        // Merge all data-types except \"function\"\n        mediaRecorder = mergeProps(mediaRecorder, this);\n\n        mediaRecorder.start(timeSlice);\n    };\n\n    this.onStartedDrawingNonBlankFrames = function() {};\n    this.clearOldRecordedFrames = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.clearOldRecordedFrames();\n    };\n\n    this.stop = function() {\n        if (mediaRecorder) {\n            mediaRecorder.stop();\n        }\n    };\n\n    this.ondataavailable = function(blob) {\n        console.log('ondataavailable..', blob);\n    };\n\n    this.onstop = function(error) {\n        console.warn('stopped..', error);\n    };\n\n    this.save = function(file, fileName) {\n        if (!file) {\n            if (!mediaRecorder) {\n                return;\n            }\n\n            ConcatenateBlobs(mediaRecorder.blobs, mediaRecorder.blobs[0].type, function(concatenatedBlob) {\n                invokeSaveAsDialog(concatenatedBlob);\n            });\n            return;\n        }\n        invokeSaveAsDialog(file, fileName);\n    };\n\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n        mediaRecorder.pause();\n        console.log('Paused recording.', this.mimeType || mediaRecorder.mimeType);\n    };\n\n    this.resume = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n        mediaRecorder.resume();\n        console.log('Resumed recording.', this.mimeType || mediaRecorder.mimeType);\n    };\n\n    // StereoAudioRecorder || WhammyRecorder || MediaRecorderWrapper || GifRecorder\n    this.recorderType = null;\n\n    // video/webm or audio/webm or audio/ogg or audio/wav\n    this.mimeType = 'video/webm';\n\n    // logs are enabled by default\n    this.disableLogs = false;\n\n    // Reference to \"MediaRecorder.js\"\n    var mediaRecorder;\n}\n\n// ______________________\n// MultiStreamRecorder.js\n\nfunction MultiStreamRecorder(mediaStream) {\n    if (!mediaStream) {\n        throw 'MediaStream is mandatory.';\n    }\n\n    var self = this;\n    var isMediaRecorder = isMediaRecorderCompatible();\n\n    this.stream = mediaStream;\n\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        audioRecorder = new MediaStreamRecorder(mediaStream);\n        videoRecorder = new MediaStreamRecorder(mediaStream);\n\n        audioRecorder.mimeType = 'audio/ogg';\n        videoRecorder.mimeType = 'video/webm';\n\n        for (var prop in this) {\n            if (typeof this[prop] !== 'function') {\n                audioRecorder[prop] = videoRecorder[prop] = this[prop];\n            }\n        }\n\n        audioRecorder.ondataavailable = function(blob) {\n            if (!audioVideoBlobs[recordingInterval]) {\n                audioVideoBlobs[recordingInterval] = {};\n            }\n\n            audioVideoBlobs[recordingInterval].audio = blob;\n\n            if (audioVideoBlobs[recordingInterval].video && !audioVideoBlobs[recordingInterval].onDataAvailableEventFired) {\n                audioVideoBlobs[recordingInterval].onDataAvailableEventFired = true;\n                fireOnDataAvailableEvent(audioVideoBlobs[recordingInterval]);\n            }\n        };\n\n        videoRecorder.ondataavailable = function(blob) {\n            if (isMediaRecorder) {\n                return self.ondataavailable({\n                    video: blob,\n                    audio: blob\n                });\n            }\n\n            if (!audioVideoBlobs[recordingInterval]) {\n                audioVideoBlobs[recordingInterval] = {};\n            }\n\n            audioVideoBlobs[recordingInterval].video = blob;\n\n            if (audioVideoBlobs[recordingInterval].audio && !audioVideoBlobs[recordingInterval].onDataAvailableEventFired) {\n                audioVideoBlobs[recordingInterval].onDataAvailableEventFired = true;\n                fireOnDataAvailableEvent(audioVideoBlobs[recordingInterval]);\n            }\n        };\n\n        function fireOnDataAvailableEvent(blobs) {\n            recordingInterval++;\n            self.ondataavailable(blobs);\n        }\n\n        videoRecorder.onstop = audioRecorder.onstop = function(error) {\n            self.onstop(error);\n        };\n\n        if (!isMediaRecorder) {\n            // to make sure both audio/video are synced.\n            videoRecorder.onStartedDrawingNonBlankFrames = function() {\n                videoRecorder.clearOldRecordedFrames();\n                audioRecorder.start(timeSlice);\n            };\n            videoRecorder.start(timeSlice);\n        } else {\n            videoRecorder.start(timeSlice);\n        }\n    };\n\n    this.stop = function() {\n        if (audioRecorder) {\n            audioRecorder.stop();\n        }\n        if (videoRecorder) {\n            videoRecorder.stop();\n        }\n    };\n\n    this.ondataavailable = function(blob) {\n        console.log('ondataavailable..', blob);\n    };\n\n    this.onstop = function(error) {\n        console.warn('stopped..', error);\n    };\n\n    this.pause = function() {\n        if (audioRecorder) {\n            audioRecorder.pause();\n        }\n        if (videoRecorder) {\n            videoRecorder.pause();\n        }\n    };\n\n    this.resume = function() {\n        if (audioRecorder) {\n            audioRecorder.resume();\n        }\n        if (videoRecorder) {\n            videoRecorder.resume();\n        }\n    };\n\n    var audioRecorder;\n    var videoRecorder;\n\n    var audioVideoBlobs = {};\n    var recordingInterval = 0;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.MultiStreamRecorder = MultiStreamRecorder;\n}\n\n// _____________________________\n// Cross-Browser-Declarations.js\n\nvar browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';\n\n(function(that) {\n    if (typeof window !== 'undefined') {\n        return;\n    }\n\n    if (typeof window === 'undefined' && typeof global !== 'undefined') {\n        global.navigator = {\n            userAgent: browserFakeUserAgent,\n            getUserMedia: function() {}\n        };\n\n        /*global window:true */\n        that.window = global;\n    } else if (typeof window === 'undefined') {\n        // window = this;\n    }\n\n    if (typeof document === 'undefined') {\n        /*global document:true */\n        that.document = {};\n\n        document.createElement = document.captureStream = document.mozCaptureStream = function() {\n            return {};\n        };\n    }\n\n    if (typeof location === 'undefined') {\n        /*global location:true */\n        that.location = {\n            protocol: 'file:',\n            href: '',\n            hash: ''\n        };\n    }\n\n    if (typeof screen === 'undefined') {\n        /*global screen:true */\n        that.screen = {\n            width: 0,\n            height: 0\n        };\n    }\n})(typeof global !== 'undefined' ? global : window);\n\n// WebAudio API representer\nvar AudioContext = window.AudioContext;\n\nif (typeof AudioContext === 'undefined') {\n    if (typeof webkitAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = webkitAudioContext;\n    }\n\n    if (typeof mozAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = mozAudioContext;\n    }\n}\n\nif (typeof window === 'undefined') {\n    /*jshint -W020 */\n    window = {};\n}\n\n// WebAudio API representer\nvar AudioContext = window.AudioContext;\n\nif (typeof AudioContext === 'undefined') {\n    if (typeof webkitAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = webkitAudioContext;\n    }\n\n    if (typeof mozAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = mozAudioContext;\n    }\n}\n\n/*jshint -W079 */\nvar URL = window.URL;\n\nif (typeof URL === 'undefined' && typeof webkitURL !== 'undefined') {\n    /*global URL:true */\n    URL = webkitURL;\n}\n\nif (typeof navigator !== 'undefined') {\n    if (typeof navigator.webkitGetUserMedia !== 'undefined') {\n        navigator.getUserMedia = navigator.webkitGetUserMedia;\n    }\n\n    if (typeof navigator.mozGetUserMedia !== 'undefined') {\n        navigator.getUserMedia = navigator.mozGetUserMedia;\n    }\n} else {\n    navigator = {\n        getUserMedia: function() {},\n        userAgent: browserFakeUserAgent\n    };\n}\n\nvar IsEdge = navigator.userAgent.indexOf('Edge') !== -1 && (!!navigator.msSaveBlob || !!navigator.msSaveOrOpenBlob);\n\nvar IsOpera = false;\nif (typeof opera !== 'undefined' && navigator.userAgent && navigator.userAgent.indexOf('OPR/') !== -1) {\n    IsOpera = true;\n}\nvar IsChrome = !IsEdge && !IsEdge && !!navigator.webkitGetUserMedia;\n\nvar MediaStream = window.MediaStream;\n\nif (typeof MediaStream === 'undefined' && typeof webkitMediaStream !== 'undefined') {\n    MediaStream = webkitMediaStream;\n}\n\n/*global MediaStream:true */\nif (typeof MediaStream !== 'undefined') {\n    if (!('getVideoTracks' in MediaStream.prototype)) {\n        MediaStream.prototype.getVideoTracks = function() {\n            if (!this.getTracks) {\n                return [];\n            }\n\n            var tracks = [];\n            this.getTracks.forEach(function(track) {\n                if (track.kind.toString().indexOf('video') !== -1) {\n                    tracks.push(track);\n                }\n            });\n            return tracks;\n        };\n\n        MediaStream.prototype.getAudioTracks = function() {\n            if (!this.getTracks) {\n                return [];\n            }\n\n            var tracks = [];\n            this.getTracks.forEach(function(track) {\n                if (track.kind.toString().indexOf('audio') !== -1) {\n                    tracks.push(track);\n                }\n            });\n            return tracks;\n        };\n    }\n\n    if (!('stop' in MediaStream.prototype)) {\n        MediaStream.prototype.stop = function() {\n            this.getAudioTracks().forEach(function(track) {\n                if (!!track.stop) {\n                    track.stop();\n                }\n            });\n\n            this.getVideoTracks().forEach(function(track) {\n                if (!!track.stop) {\n                    track.stop();\n                }\n            });\n        };\n    }\n}\n\nif (typeof location !== 'undefined') {\n    if (location.href.indexOf('file:') === 0) {\n        console.error('Please load this HTML file on HTTP or HTTPS.');\n    }\n}\n\n// Merge all other data-types except \"function\"\n\nfunction mergeProps(mergein, mergeto) {\n    for (var t in mergeto) {\n        if (typeof mergeto[t] !== 'function') {\n            mergein[t] = mergeto[t];\n        }\n    }\n    return mergein;\n}\n\n// \"dropFirstFrame\" has been added by Graham Roth\n// https://github.com/gsroth\n\nfunction dropFirstFrame(arr) {\n    arr.shift();\n    return arr;\n}\n\n/**\n * @param {Blob} file - File or Blob object. This parameter is required.\n * @param {string} fileName - Optional file name e.g. \"Recorded-Video.webm\"\n * @example\n * invokeSaveAsDialog(blob or file, [optional] fileName);\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\n */\nfunction invokeSaveAsDialog(file, fileName) {\n    if (!file) {\n        throw 'Blob object is required.';\n    }\n\n    if (!file.type) {\n        try {\n            file.type = 'video/webm';\n        } catch (e) {}\n    }\n\n    var fileExtension = (file.type || 'video/webm').split('/')[1];\n\n    if (fileName && fileName.indexOf('.') !== -1) {\n        var splitted = fileName.split('.');\n        fileName = splitted[0];\n        fileExtension = splitted[1];\n    }\n\n    var fileFullName = (fileName || (Math.round(Math.random() * 9999999999) + 888888888)) + '.' + fileExtension;\n\n    if (typeof navigator.msSaveOrOpenBlob !== 'undefined') {\n        return navigator.msSaveOrOpenBlob(file, fileFullName);\n    } else if (typeof navigator.msSaveBlob !== 'undefined') {\n        return navigator.msSaveBlob(file, fileFullName);\n    }\n\n    var hyperlink = document.createElement('a');\n    hyperlink.href = URL.createObjectURL(file);\n    hyperlink.target = '_blank';\n    hyperlink.download = fileFullName;\n\n    if (!!navigator.mozGetUserMedia) {\n        hyperlink.onclick = function() {\n            (document.body || document.documentElement).removeChild(hyperlink);\n        };\n        (document.body || document.documentElement).appendChild(hyperlink);\n    }\n\n    var evt = new MouseEvent('click', {\n        view: window,\n        bubbles: true,\n        cancelable: true\n    });\n\n    hyperlink.dispatchEvent(evt);\n\n    if (!navigator.mozGetUserMedia) {\n        URL.revokeObjectURL(hyperlink.href);\n    }\n}\n\nfunction bytesToSize(bytes) {\n    var k = 1000;\n    var sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\n    if (bytes === 0) {\n        return '0 Bytes';\n    }\n    var i = parseInt(Math.floor(Math.log(bytes) / Math.log(k)), 10);\n    return (bytes / Math.pow(k, i)).toPrecision(3) + ' ' + sizes[i];\n}\n\n// ______________ (used to handle stuff like http://goo.gl/xmE5eg) issue #129\n// ObjectStore.js\nvar ObjectStore = {\n    AudioContext: AudioContext\n};\n\nfunction isMediaRecorderCompatible() {\n    var isOpera = !!window.opera || navigator.userAgent.indexOf(' OPR/') >= 0;\n    var isChrome = !!window.chrome && !isOpera;\n    var isFirefox = typeof window.InstallTrigger !== 'undefined';\n\n    if (isFirefox) {\n        return true;\n    }\n\n    if (!isChrome) {\n        return false;\n    }\n\n    var nVer = navigator.appVersion;\n    var nAgt = navigator.userAgent;\n    var fullVersion = '' + parseFloat(navigator.appVersion);\n    var majorVersion = parseInt(navigator.appVersion, 10);\n    var nameOffset, verOffset, ix;\n\n    if (isChrome) {\n        verOffset = nAgt.indexOf('Chrome');\n        fullVersion = nAgt.substring(verOffset + 7);\n    }\n\n    // trim the fullVersion string at semicolon/space if present\n    if ((ix = fullVersion.indexOf(';')) !== -1) {\n        fullVersion = fullVersion.substring(0, ix);\n    }\n\n    if ((ix = fullVersion.indexOf(' ')) !== -1) {\n        fullVersion = fullVersion.substring(0, ix);\n    }\n\n    majorVersion = parseInt('' + fullVersion, 10);\n\n    if (isNaN(majorVersion)) {\n        fullVersion = '' + parseFloat(navigator.appVersion);\n        majorVersion = parseInt(navigator.appVersion, 10);\n    }\n\n    return majorVersion >= 49;\n}\n\n// ______________ (used to handle stuff like http://goo.gl/xmE5eg) issue #129\n// ObjectStore.js\nvar ObjectStore = {\n    AudioContext: window.AudioContext || window.webkitAudioContext\n};\n\n// ==================\n// MediaRecorder.js\n\n/**\n * Implementation of https://dvcs.w3.org/hg/dap/raw-file/default/media-stream-capture/MediaRecorder.html\n * The MediaRecorder accepts a mediaStream as input source passed from UA. When recorder starts,\n * a MediaEncoder will be created and accept the mediaStream as input source.\n * Encoder will get the raw data by track data changes, encode it by selected MIME Type, then store the encoded in EncodedBufferCache object.\n * The encoded data will be extracted on every timeslice passed from Start function call or by RequestData function.\n * Thread model:\n * When the recorder starts, it creates a \"Media Encoder\" thread to read data from MediaEncoder object and store buffer in EncodedBufferCache object.\n * Also extract the encoded data and create blobs on every timeslice passed from start function or RequestData function called by UA.\n */\n\nfunction MediaRecorderWrapper(mediaStream) {\n    var self = this;\n\n    /**\n     * This method records MediaStream.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.record();\n     */\n    this.start = function(timeSlice, __disableLogs) {\n        if (!self.mimeType) {\n            self.mimeType = 'video/webm';\n        }\n\n        if (self.mimeType.indexOf('audio') !== -1) {\n            if (mediaStream.getVideoTracks().length && mediaStream.getAudioTracks().length) {\n                var stream;\n                if (!!navigator.mozGetUserMedia) {\n                    stream = new MediaStream();\n                    stream.addTrack(mediaStream.getAudioTracks()[0]);\n                } else {\n                    // webkitMediaStream\n                    stream = new MediaStream(mediaStream.getAudioTracks());\n                }\n                mediaStream = stream;\n            }\n        }\n\n        if (self.mimeType.indexOf('audio') !== -1) {\n            self.mimeType = IsChrome ? 'audio/webm' : 'audio/ogg';\n        }\n\n        self.dontFireOnDataAvailableEvent = false;\n\n        var recorderHints = {\n            mimeType: self.mimeType\n        };\n\n        if (!self.disableLogs && !__disableLogs) {\n            console.log('Passing following params over MediaRecorder API.', recorderHints);\n        }\n\n        if (mediaRecorder) {\n            // mandatory to make sure Firefox doesn't fails to record streams 3-4 times without reloading the page.\n            mediaRecorder = null;\n        }\n\n        if (IsChrome && !isMediaRecorderCompatible()) {\n            // to support video-only recording on stable\n            recorderHints = 'video/vp8';\n        }\n\n        // http://dxr.mozilla.org/mozilla-central/source/content/media/MediaRecorder.cpp\n        // https://wiki.mozilla.org/Gecko:MediaRecorder\n        // https://dvcs.w3.org/hg/dap/raw-file/default/media-stream-capture/MediaRecorder.html\n\n        // starting a recording session; which will initiate \"Reading Thread\"\n        // \"Reading Thread\" are used to prevent main-thread blocking scenarios\n        try {\n            mediaRecorder = new MediaRecorder(mediaStream, recorderHints);\n        } catch (e) {\n            // if someone passed NON_supported mimeType\n            // or if Firefox on Android\n            mediaRecorder = new MediaRecorder(mediaStream);\n        }\n\n        if ('canRecordMimeType' in mediaRecorder && mediaRecorder.canRecordMimeType(self.mimeType) === false) {\n            if (!self.disableLogs) {\n                console.warn('MediaRecorder API seems unable to record mimeType:', self.mimeType);\n            }\n        }\n\n        // i.e. stop recording when <video> is paused by the user; and auto restart recording \n        // when video is resumed. E.g. yourStream.getVideoTracks()[0].muted = true; // it will auto-stop recording.\n        mediaRecorder.ignoreMutedMedia = self.ignoreMutedMedia || false;\n\n        var firedOnDataAvailableOnce = false;\n\n        // Dispatching OnDataAvailable Handler\n        mediaRecorder.ondataavailable = function(e) {\n            if (self.dontFireOnDataAvailableEvent) {\n                return;\n            }\n\n            // how to fix FF-corrupt-webm issues?\n            // should we leave this?          e.data.size < 26800\n            if (!e.data || !e.data.size || e.data.size < 26800 || firedOnDataAvailableOnce) {\n                return;\n            }\n\n            firedOnDataAvailableOnce = true;\n\n            var blob = self.getNativeBlob ? e.data : new Blob([e.data], {\n                type: self.mimeType || 'video/webm'\n            });\n\n            self.ondataavailable(blob);\n\n            self.dontFireOnDataAvailableEvent = true;\n\n            if (!!mediaRecorder) {\n                mediaRecorder.stop();\n                mediaRecorder = null;\n            }\n\n            // record next interval\n            self.start(timeSlice, '__disableLogs');\n        };\n\n        mediaRecorder.onerror = function(error) {\n            if (!self.disableLogs) {\n                if (error.name === 'InvalidState') {\n                    console.error('The MediaRecorder is not in a state in which the proposed operation is allowed to be executed.');\n                } else if (error.name === 'OutOfMemory') {\n                    console.error('The UA has exhaused the available memory. User agents SHOULD provide as much additional information as possible in the message attribute.');\n                } else if (error.name === 'IllegalStreamModification') {\n                    console.error('A modification to the stream has occurred that makes it impossible to continue recording. An example would be the addition of a Track while recording is occurring. User agents SHOULD provide as much additional information as possible in the message attribute.');\n                } else if (error.name === 'OtherRecordingError') {\n                    console.error('Used for an fatal error other than those listed above. User agents SHOULD provide as much additional information as possible in the message attribute.');\n                } else if (error.name === 'GenericError') {\n                    console.error('The UA cannot provide the codec or recording option that has been requested.', error);\n                } else {\n                    console.error('MediaRecorder Error', error);\n                }\n            }\n\n            // When the stream is \"ended\" set recording to 'inactive' \n            // and stop gathering data. Callers should not rely on \n            // exactness of the timeSlice value, especially \n            // if the timeSlice value is small. Callers should \n            // consider timeSlice as a minimum value\n\n            if (!!mediaRecorder && mediaRecorder.state !== 'inactive' && mediaRecorder.state !== 'stopped') {\n                mediaRecorder.stop();\n            }\n        };\n\n        // void start(optional long mTimeSlice)\n        // The interval of passing encoded data from EncodedBufferCache to onDataAvailable\n        // handler. \"mTimeSlice < 0\" means Session object does not push encoded data to\n        // onDataAvailable, instead, it passive wait the client side pull encoded data\n        // by calling requestData API.\n        try {\n            mediaRecorder.start(3.6e+6);\n        } catch (e) {\n            mediaRecorder = null;\n        }\n\n        setTimeout(function() {\n            if (!mediaRecorder) {\n                return;\n            }\n\n            if (mediaRecorder.state === 'recording') {\n                // \"stop\" method auto invokes \"requestData\"!\n                mediaRecorder.requestData();\n                // mediaRecorder.stop();\n            }\n        }, timeSlice);\n\n        // Start recording. If timeSlice has been provided, mediaRecorder will\n        // raise a dataavailable event containing the Blob of collected data on every timeSlice milliseconds.\n        // If timeSlice isn't provided, UA should call the RequestData to obtain the Blob data, also set the mTimeSlice to zero.\n    };\n\n    /**\n     * This method stops recording MediaStream.\n     * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.stop(function(blob) {\n     *     video.src = URL.createObjectURL(blob);\n     * });\n     */\n    this.stop = function(callback) {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        // mediaRecorder.state === 'recording' means that media recorder is associated with \"session\"\n        // mediaRecorder.state === 'stopped' means that media recorder is detached from the \"session\" ... in this case; \"session\" will also be deleted.\n\n        if (mediaRecorder.state === 'recording') {\n            // \"stop\" method auto invokes \"requestData\"!\n            mediaRecorder.requestData();\n\n            setTimeout(function() {\n                self.dontFireOnDataAvailableEvent = true;\n                if (!!mediaRecorder && mediaRecorder.state === 'recording') {\n                    mediaRecorder.stop();\n                }\n                mediaRecorder = null;\n            }, 2000);\n        }\n    };\n\n    /**\n     * This method pauses the recording process.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.pause();\n     */\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        if (mediaRecorder.state === 'recording') {\n            mediaRecorder.pause();\n        }\n    };\n\n    /**\n     * The recorded blobs are passed over this event.\n     * @event\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.ondataavailable = function(data) {};\n     */\n    this.ondataavailable = function(blob) {\n        console.log('recorded-blob', blob);\n    };\n\n    /**\n     * This method resumes the recording process.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.resume();\n     */\n    this.resume = function() {\n        if (this.dontFireOnDataAvailableEvent) {\n            this.dontFireOnDataAvailableEvent = false;\n\n            var disableLogs = self.disableLogs;\n            self.disableLogs = true;\n            this.record();\n            self.disableLogs = disableLogs;\n            return;\n        }\n\n        if (!mediaRecorder) {\n            return;\n        }\n\n        if (mediaRecorder.state === 'paused') {\n            mediaRecorder.resume();\n        }\n    };\n\n    /**\n     * This method resets currently recorded data.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.clearRecordedData();\n     */\n    this.clearRecordedData = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        this.pause();\n\n        this.dontFireOnDataAvailableEvent = true;\n        this.stop();\n    };\n\n    // Reference to \"MediaRecorder\" object\n    var mediaRecorder;\n\n    function isMediaStreamActive() {\n        if ('active' in mediaStream) {\n            if (!mediaStream.active) {\n                return false;\n            }\n        } else if ('ended' in mediaStream) { // old hack\n            if (mediaStream.ended) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    // this method checks if media stream is stopped\n    // or any track is ended.\n    (function looper() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        if (isMediaStreamActive() === false) {\n            self.stop();\n            return;\n        }\n\n        setTimeout(looper, 1000); // check every second\n    })();\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.MediaRecorderWrapper = MediaRecorderWrapper;\n}\n\n// ======================\n// StereoAudioRecorder.js\n\nfunction StereoAudioRecorder(mediaStream) {\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        timeSlice = timeSlice || 1000;\n\n        mediaRecorder = new StereoAudioRecorderHelper(mediaStream, this);\n\n        mediaRecorder.record();\n\n        timeout = setInterval(function() {\n            mediaRecorder.requestData();\n        }, timeSlice);\n    };\n\n    this.stop = function() {\n        if (mediaRecorder) {\n            mediaRecorder.stop();\n            clearTimeout(timeout);\n        }\n    };\n\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.pause();\n    };\n\n    this.resume = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.resume();\n    };\n\n    this.ondataavailable = function() {};\n\n    // Reference to \"StereoAudioRecorder\" object\n    var mediaRecorder;\n    var timeout;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.StereoAudioRecorder = StereoAudioRecorder;\n}\n\n// ============================\n// StereoAudioRecorderHelper.js\n\n// source code from: http://typedarray.org/wp-content/projects/WebAudioRecorder/script.js\n\nfunction StereoAudioRecorderHelper(mediaStream, root) {\n\n    // variables    \n    var deviceSampleRate = 44100; // range: 22050 to 96000\n\n    if (!ObjectStore.AudioContextConstructor) {\n        ObjectStore.AudioContextConstructor = new ObjectStore.AudioContext();\n    }\n\n    // check device sample rate\n    deviceSampleRate = ObjectStore.AudioContextConstructor.sampleRate;\n\n    var leftchannel = [];\n    var rightchannel = [];\n    var scriptprocessornode;\n    var recording = false;\n    var recordingLength = 0;\n    var volume;\n    var audioInput;\n    var sampleRate = root.sampleRate || deviceSampleRate;\n\n    var mimeType = root.mimeType || 'audio/wav';\n    var isPCM = mimeType.indexOf('audio/pcm') > -1;\n\n    var context;\n\n    var numChannels = root.audioChannels || 2;\n\n    this.record = function() {\n        recording = true;\n        // reset the buffers for the new recording\n        leftchannel.length = rightchannel.length = 0;\n        recordingLength = 0;\n    };\n\n    this.requestData = function() {\n        if (isPaused) {\n            return;\n        }\n\n        if (recordingLength === 0) {\n            requestDataInvoked = false;\n            return;\n        }\n\n        requestDataInvoked = true;\n        // clone stuff\n        var internalLeftChannel = leftchannel.slice(0);\n        var internalRightChannel = rightchannel.slice(0);\n        var internalRecordingLength = recordingLength;\n\n        // reset the buffers for the new recording\n        leftchannel.length = rightchannel.length = [];\n        recordingLength = 0;\n        requestDataInvoked = false;\n\n        // we flat the left and right channels down\n        var leftBuffer = mergeBuffers(internalLeftChannel, internalRecordingLength);\n\n        var interleaved = leftBuffer;\n\n        // we interleave both channels together\n        if (numChannels === 2) {\n            var rightBuffer = mergeBuffers(internalRightChannel, internalRecordingLength); // bug fixed via #70,#71\n            interleaved = interleave(leftBuffer, rightBuffer);\n        }\n\n        if (isPCM) {\n            // our final binary blob\n            var blob = new Blob([convertoFloat32ToInt16(interleaved)], {\n                type: 'audio/pcm'\n            });\n\n            console.debug('audio recorded blob size:', bytesToSize(blob.size));\n            root.ondataavailable(blob);\n            return;\n        }\n\n        // we create our wav file\n        var buffer = new ArrayBuffer(44 + interleaved.length * 2);\n        var view = new DataView(buffer);\n\n        // RIFF chunk descriptor\n        writeUTFBytes(view, 0, 'RIFF');\n\n        // -8 (via #97)\n        view.setUint32(4, 44 + interleaved.length * 2 - 8, true);\n\n        writeUTFBytes(view, 8, 'WAVE');\n        // FMT sub-chunk\n        writeUTFBytes(view, 12, 'fmt ');\n        view.setUint32(16, 16, true);\n        view.setUint16(20, 1, true);\n        // stereo (2 channels)\n        view.setUint16(22, numChannels, true);\n        view.setUint32(24, sampleRate, true);\n        view.setUint32(28, sampleRate * numChannels * 2, true); // numChannels * 2 (via #71)\n        view.setUint16(32, numChannels * 2, true);\n        view.setUint16(34, 16, true);\n        // data sub-chunk\n        writeUTFBytes(view, 36, 'data');\n        view.setUint32(40, interleaved.length * 2, true);\n\n        // write the PCM samples\n        var lng = interleaved.length;\n        var index = 44;\n        var volume = 1;\n        for (var i = 0; i < lng; i++) {\n            view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);\n            index += 2;\n        }\n\n        // our final binary blob\n        var blob = new Blob([view], {\n            type: 'audio/wav'\n        });\n\n        console.debug('audio recorded blob size:', bytesToSize(blob.size));\n\n        root.ondataavailable(blob);\n    };\n\n    this.stop = function() {\n        // we stop recording\n        recording = false;\n        this.requestData();\n\n        audioInput.disconnect();\n    };\n\n    function interleave(leftChannel, rightChannel) {\n        var length = leftChannel.length + rightChannel.length;\n        var result = new Float32Array(length);\n\n        var inputIndex = 0;\n\n        for (var index = 0; index < length;) {\n            result[index++] = leftChannel[inputIndex];\n            result[index++] = rightChannel[inputIndex];\n            inputIndex++;\n        }\n        return result;\n    }\n\n    function mergeBuffers(channelBuffer, recordingLength) {\n        var result = new Float32Array(recordingLength);\n        var offset = 0;\n        var lng = channelBuffer.length;\n        for (var i = 0; i < lng; i++) {\n            var buffer = channelBuffer[i];\n            result.set(buffer, offset);\n            offset += buffer.length;\n        }\n        return result;\n    }\n\n    function writeUTFBytes(view, offset, string) {\n        var lng = string.length;\n        for (var i = 0; i < lng; i++) {\n            view.setUint8(offset + i, string.charCodeAt(i));\n        }\n    }\n\n    function convertoFloat32ToInt16(buffer) {\n        var l = buffer.length;\n        var buf = new Int16Array(l)\n\n        while (l--) {\n            buf[l] = buffer[l] * 0xFFFF; //convert to 16 bit\n        }\n        return buf.buffer\n    }\n\n    // creates the audio context\n    var context = ObjectStore.AudioContextConstructor;\n\n    // creates a gain node\n    ObjectStore.VolumeGainNode = context.createGain();\n\n    var volume = ObjectStore.VolumeGainNode;\n\n    // creates an audio node from the microphone incoming stream\n    ObjectStore.AudioInput = context.createMediaStreamSource(mediaStream);\n\n    // creates an audio node from the microphone incoming stream\n    var audioInput = ObjectStore.AudioInput;\n\n    // connect the stream to the gain node\n    audioInput.connect(volume);\n\n    /* From the spec: This value controls how frequently the audioprocess event is\n    dispatched and how many sample-frames need to be processed each call.\n    Lower values for buffer size will result in a lower (better) latency.\n    Higher values will be necessary to avoid audio breakup and glitches \n    Legal values are 256, 512, 1024, 2048, 4096, 8192, and 16384.*/\n    var bufferSize = root.bufferSize || 2048;\n    if (root.bufferSize === 0) {\n        bufferSize = 0;\n    }\n\n    if (context.createJavaScriptNode) {\n        scriptprocessornode = context.createJavaScriptNode(bufferSize, numChannels, numChannels);\n    } else if (context.createScriptProcessor) {\n        scriptprocessornode = context.createScriptProcessor(bufferSize, numChannels, numChannels);\n    } else {\n        throw 'WebAudio API has no support on this browser.';\n    }\n\n    bufferSize = scriptprocessornode.bufferSize;\n\n    console.debug('using audio buffer-size:', bufferSize);\n\n    var requestDataInvoked = false;\n\n    // sometimes \"scriptprocessornode\" disconnects from he destination-node\n    // and there is no exception thrown in this case.\n    // and obviously no further \"ondataavailable\" events will be emitted.\n    // below global-scope variable is added to debug such unexpected but \"rare\" cases.\n    window.scriptprocessornode = scriptprocessornode;\n\n    if (numChannels === 1) {\n        console.debug('All right-channels are skipped.');\n    }\n\n    var isPaused = false;\n\n    this.pause = function() {\n        isPaused = true;\n    };\n\n    this.resume = function() {\n        isPaused = false;\n    };\n\n    // http://webaudio.github.io/web-audio-api/#the-scriptprocessornode-interface\n    scriptprocessornode.onaudioprocess = function(e) {\n        if (!recording || requestDataInvoked || isPaused) {\n            return;\n        }\n\n        var left = e.inputBuffer.getChannelData(0);\n        leftchannel.push(new Float32Array(left));\n\n        if (numChannels === 2) {\n            var right = e.inputBuffer.getChannelData(1);\n            rightchannel.push(new Float32Array(right));\n        }\n        recordingLength += bufferSize;\n    };\n\n    volume.connect(scriptprocessornode);\n    scriptprocessornode.connect(context.destination);\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.StereoAudioRecorderHelper = StereoAudioRecorderHelper;\n}\n\n// ===================\n// WhammyRecorder.js\n\nfunction WhammyRecorder(mediaStream) {\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        timeSlice = timeSlice || 1000;\n\n        mediaRecorder = new WhammyRecorderHelper(mediaStream, this);\n\n        for (var prop in this) {\n            if (typeof this[prop] !== 'function') {\n                mediaRecorder[prop] = this[prop];\n            }\n        }\n\n        mediaRecorder.record();\n\n        timeout = setInterval(function() {\n            mediaRecorder.requestData();\n        }, timeSlice);\n    };\n\n    this.stop = function() {\n        if (mediaRecorder) {\n            mediaRecorder.stop();\n            clearTimeout(timeout);\n        }\n    };\n\n    this.clearOldRecordedFrames = function() {\n        if (mediaRecorder) {\n            mediaRecorder.clearOldRecordedFrames();\n        }\n    };\n\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.pause();\n    };\n\n    this.resume = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.resume();\n    };\n\n    this.ondataavailable = function() {};\n\n    // Reference to \"WhammyRecorder\" object\n    var mediaRecorder;\n    var timeout;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.WhammyRecorder = WhammyRecorder;\n}\n\n// ==========================\n// WhammyRecorderHelper.js\n\nfunction WhammyRecorderHelper(mediaStream, root) {\n    this.record = function(timeSlice) {\n        if (!this.width) {\n            this.width = 320;\n        }\n        if (!this.height) {\n            this.height = 240;\n        }\n\n        if (this.video && this.video instanceof HTMLVideoElement) {\n            if (!this.width) {\n                this.width = video.videoWidth || video.clientWidth || 320;\n            }\n            if (!this.height) {\n                this.height = video.videoHeight || video.clientHeight || 240;\n            }\n        }\n\n        if (!this.video) {\n            this.video = {\n                width: this.width,\n                height: this.height\n            };\n        }\n\n        if (!this.canvas || !this.canvas.width || !this.canvas.height) {\n            this.canvas = {\n                width: this.width,\n                height: this.height\n            };\n        }\n\n        canvas.width = this.canvas.width;\n        canvas.height = this.canvas.height;\n\n        // setting defaults\n        if (this.video && this.video instanceof HTMLVideoElement) {\n            this.isHTMLObject = true;\n            video = this.video.cloneNode();\n        } else {\n            video = document.createElement('video');\n            video.src = URL.createObjectURL(mediaStream);\n\n            video.width = this.video.width;\n            video.height = this.video.height;\n        }\n\n        video.muted = true;\n        video.play();\n\n        lastTime = new Date().getTime();\n        whammy = new Whammy.Video(root.speed, root.quality);\n\n        console.log('canvas resolutions', canvas.width, '*', canvas.height);\n        console.log('video width/height', video.width || canvas.width, '*', video.height || canvas.height);\n\n        drawFrames();\n    };\n\n    this.clearOldRecordedFrames = function() {\n        whammy.frames = [];\n    };\n\n    var requestDataInvoked = false;\n    this.requestData = function() {\n        if (isPaused) {\n            return;\n        }\n\n        if (!whammy.frames.length) {\n            requestDataInvoked = false;\n            return;\n        }\n\n        requestDataInvoked = true;\n        // clone stuff\n        var internalFrames = whammy.frames.slice(0);\n\n        // reset the frames for the new recording\n\n        whammy.frames = dropBlackFrames(internalFrames, -1);\n\n        whammy.compile(function(whammyBlob) {\n            root.ondataavailable(whammyBlob);\n            console.debug('video recorded blob size:', bytesToSize(whammyBlob.size));\n        });\n\n        whammy.frames = [];\n\n        requestDataInvoked = false;\n    };\n\n    var isOnStartedDrawingNonBlankFramesInvoked = false;\n\n    function drawFrames() {\n        if (isPaused) {\n            lastTime = new Date().getTime();\n            setTimeout(drawFrames, 500);\n            return;\n        }\n\n        if (isStopDrawing) {\n            return;\n        }\n\n        if (requestDataInvoked) {\n            return setTimeout(drawFrames, 100);\n        }\n\n        var duration = new Date().getTime() - lastTime;\n        if (!duration) {\n            return drawFrames();\n        }\n\n        // via webrtc-experiment#206, by Jack i.e. @Seymourr\n        lastTime = new Date().getTime();\n\n        if (!self.isHTMLObject && video.paused) {\n            video.play(); // Android\n        }\n\n        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n        if (!isStopDrawing) {\n            whammy.frames.push({\n                duration: duration,\n                image: canvas.toDataURL('image/webp')\n            });\n        }\n\n        if (!isOnStartedDrawingNonBlankFramesInvoked && !isBlankFrame(whammy.frames[whammy.frames.length - 1])) {\n            isOnStartedDrawingNonBlankFramesInvoked = true;\n            root.onStartedDrawingNonBlankFrames();\n        }\n\n        setTimeout(drawFrames, 10);\n    }\n\n    var isStopDrawing = false;\n\n    this.stop = function() {\n        isStopDrawing = true;\n        this.requestData();\n    };\n\n    var canvas = document.createElement('canvas');\n    var context = canvas.getContext('2d');\n\n    var video;\n    var lastTime;\n    var whammy;\n\n    var self = this;\n\n    function isBlankFrame(frame, _pixTolerance, _frameTolerance) {\n        var localCanvas = document.createElement('canvas');\n        localCanvas.width = canvas.width;\n        localCanvas.height = canvas.height;\n        var context2d = localCanvas.getContext('2d');\n\n        var sampleColor = {\n            r: 0,\n            g: 0,\n            b: 0\n        };\n        var maxColorDifference = Math.sqrt(\n            Math.pow(255, 2) +\n            Math.pow(255, 2) +\n            Math.pow(255, 2)\n        );\n        var pixTolerance = _pixTolerance && _pixTolerance >= 0 && _pixTolerance <= 1 ? _pixTolerance : 0;\n        var frameTolerance = _frameTolerance && _frameTolerance >= 0 && _frameTolerance <= 1 ? _frameTolerance : 0;\n\n        var matchPixCount, endPixCheck, maxPixCount;\n\n        var image = new Image();\n        image.src = frame.image;\n        context2d.drawImage(image, 0, 0, canvas.width, canvas.height);\n        var imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);\n        matchPixCount = 0;\n        endPixCheck = imageData.data.length;\n        maxPixCount = imageData.data.length / 4;\n\n        for (var pix = 0; pix < endPixCheck; pix += 4) {\n            var currentColor = {\n                r: imageData.data[pix],\n                g: imageData.data[pix + 1],\n                b: imageData.data[pix + 2]\n            };\n            var colorDifference = Math.sqrt(\n                Math.pow(currentColor.r - sampleColor.r, 2) +\n                Math.pow(currentColor.g - sampleColor.g, 2) +\n                Math.pow(currentColor.b - sampleColor.b, 2)\n            );\n            // difference in color it is difference in color vectors (r1,g1,b1) <=> (r2,g2,b2)\n            if (colorDifference <= maxColorDifference * pixTolerance) {\n                matchPixCount++;\n            }\n        }\n\n        if (maxPixCount - matchPixCount <= maxPixCount * frameTolerance) {\n            return false;\n        } else {\n            return true;\n        }\n    }\n\n    function dropBlackFrames(_frames, _framesToCheck, _pixTolerance, _frameTolerance) {\n        var localCanvas = document.createElement('canvas');\n        localCanvas.width = canvas.width;\n        localCanvas.height = canvas.height;\n        var context2d = localCanvas.getContext('2d');\n        var resultFrames = [];\n\n        var checkUntilNotBlack = _framesToCheck === -1;\n        var endCheckFrame = (_framesToCheck && _framesToCheck > 0 && _framesToCheck <= _frames.length) ?\n            _framesToCheck : _frames.length;\n        var sampleColor = {\n            r: 0,\n            g: 0,\n            b: 0\n        };\n        var maxColorDifference = Math.sqrt(\n            Math.pow(255, 2) +\n            Math.pow(255, 2) +\n            Math.pow(255, 2)\n        );\n        var pixTolerance = _pixTolerance && _pixTolerance >= 0 && _pixTolerance <= 1 ? _pixTolerance : 0;\n        var frameTolerance = _frameTolerance && _frameTolerance >= 0 && _frameTolerance <= 1 ? _frameTolerance : 0;\n        var doNotCheckNext = false;\n\n        for (var f = 0; f < endCheckFrame; f++) {\n            var matchPixCount, endPixCheck, maxPixCount;\n\n            if (!doNotCheckNext) {\n                var image = new Image();\n                image.src = _frames[f].image;\n                context2d.drawImage(image, 0, 0, canvas.width, canvas.height);\n                var imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);\n                matchPixCount = 0;\n                endPixCheck = imageData.data.length;\n                maxPixCount = imageData.data.length / 4;\n\n                for (var pix = 0; pix < endPixCheck; pix += 4) {\n                    var currentColor = {\n                        r: imageData.data[pix],\n                        g: imageData.data[pix + 1],\n                        b: imageData.data[pix + 2]\n                    };\n                    var colorDifference = Math.sqrt(\n                        Math.pow(currentColor.r - sampleColor.r, 2) +\n                        Math.pow(currentColor.g - sampleColor.g, 2) +\n                        Math.pow(currentColor.b - sampleColor.b, 2)\n                    );\n                    // difference in color it is difference in color vectors (r1,g1,b1) <=> (r2,g2,b2)\n                    if (colorDifference <= maxColorDifference * pixTolerance) {\n                        matchPixCount++;\n                    }\n                }\n            }\n\n            if (!doNotCheckNext && maxPixCount - matchPixCount <= maxPixCount * frameTolerance) {\n                // console.log('removed black frame : ' + f + ' ; frame duration ' + _frames[f].duration);\n            } else {\n                // console.log('frame is passed : ' + f);\n                if (checkUntilNotBlack) {\n                    doNotCheckNext = true;\n                }\n                resultFrames.push(_frames[f]);\n            }\n        }\n\n        resultFrames = resultFrames.concat(_frames.slice(endCheckFrame));\n\n        if (resultFrames.length <= 0) {\n            // at least one last frame should be available for next manipulation\n            // if total duration of all frames will be < 1000 than ffmpeg doesn't work well...\n            resultFrames.push(_frames[_frames.length - 1]);\n        }\n\n        return resultFrames;\n    }\n\n    var isPaused = false;\n\n    this.pause = function() {\n        isPaused = true;\n    };\n\n    this.resume = function() {\n        isPaused = false;\n    };\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.WhammyRecorderHelper = WhammyRecorderHelper;\n}\n\n// --------------\n// GifRecorder.js\n\nfunction GifRecorder(mediaStream) {\n    if (typeof GIFEncoder === 'undefined') {\n        throw 'Please link: https://cdn.webrtc-experiment.com/gif-recorder.js';\n    }\n\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        timeSlice = timeSlice || 1000;\n\n        var imageWidth = this.videoWidth || 320;\n        var imageHeight = this.videoHeight || 240;\n\n        canvas.width = video.width = imageWidth;\n        canvas.height = video.height = imageHeight;\n\n        // external library to record as GIF images\n        gifEncoder = new GIFEncoder();\n\n        // void setRepeat(int iter)\n        // Sets the number of times the set of GIF frames should be played.\n        // Default is 1; 0 means play indefinitely.\n        gifEncoder.setRepeat(0);\n\n        // void setFrameRate(Number fps)\n        // Sets frame rate in frames per second.\n        // Equivalent to setDelay(1000/fps).\n        // Using \"setDelay\" instead of \"setFrameRate\"\n        gifEncoder.setDelay(this.frameRate || this.speed || 200);\n\n        // void setQuality(int quality)\n        // Sets quality of color quantization (conversion of images to the\n        // maximum 256 colors allowed by the GIF specification).\n        // Lower values (minimum = 1) produce better colors,\n        // but slow processing significantly. 10 is the default,\n        // and produces good color mapping at reasonable speeds.\n        // Values greater than 20 do not yield significant improvements in speed.\n        gifEncoder.setQuality(this.quality || 1);\n\n        // Boolean start()\n        // This writes the GIF Header and returns false if it fails.\n        gifEncoder.start();\n\n        startTime = Date.now();\n\n        function drawVideoFrame(time) {\n            if (isPaused) {\n                setTimeout(drawVideoFrame, 500, time);\n                return;\n            }\n\n            lastAnimationFrame = requestAnimationFrame(drawVideoFrame);\n\n            if (typeof lastFrameTime === undefined) {\n                lastFrameTime = time;\n            }\n\n            // ~10 fps\n            if (time - lastFrameTime < 90) {\n                return;\n            }\n\n            if (video.paused) {\n                video.play(); // Android\n            }\n\n            context.drawImage(video, 0, 0, imageWidth, imageHeight);\n\n            gifEncoder.addFrame(context);\n\n            // console.log('Recording...' + Math.round((Date.now() - startTime) / 1000) + 's');\n            // console.log(\"fps: \", 1000 / (time - lastFrameTime));\n\n            lastFrameTime = time;\n        }\n\n        lastAnimationFrame = requestAnimationFrame(drawVideoFrame);\n\n        timeout = setTimeout(doneRecording, timeSlice);\n    };\n\n    function doneRecording() {\n        endTime = Date.now();\n\n        var gifBlob = new Blob([new Uint8Array(gifEncoder.stream().bin)], {\n            type: 'image/gif'\n        });\n        self.ondataavailable(gifBlob);\n\n        // todo: find a way to clear old recorded blobs\n        gifEncoder.stream().bin = [];\n    }\n\n    this.stop = function() {\n        if (lastAnimationFrame) {\n            cancelAnimationFrame(lastAnimationFrame);\n            clearTimeout(timeout);\n            doneRecording();\n        }\n    };\n\n    var isPaused = false;\n\n    this.pause = function() {\n        isPaused = true;\n    };\n\n    this.resume = function() {\n        isPaused = false;\n    };\n\n    this.ondataavailable = function() {};\n    this.onstop = function() {};\n\n    // Reference to itself\n    var self = this;\n\n    var canvas = document.createElement('canvas');\n    var context = canvas.getContext('2d');\n\n    var video = document.createElement('video');\n    video.muted = true;\n    video.autoplay = true;\n    video.src = URL.createObjectURL(mediaStream);\n    video.play();\n\n    var lastAnimationFrame = null;\n    var startTime, endTime, lastFrameTime;\n\n    var gifEncoder;\n    var timeout;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.GifRecorder = GifRecorder;\n}\n\n// https://github.com/antimatter15/whammy/blob/master/LICENSE\n// _________\n// Whammy.js\n\n// todo: Firefox now supports webp for webm containers!\n// their MediaRecorder implementation works well!\n// should we provide an option to record via Whammy.js or MediaRecorder API is a better solution?\n\n/**\n * Whammy is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It is written by {@link https://github.com/antimatter15|antimatter15}\n * @summary A real time javascript webm encoder based on a canvas hack.\n * @typedef Whammy\n * @class\n * @example\n * var recorder = new Whammy().Video(15);\n * recorder.add(context || canvas || dataURL);\n * var output = recorder.compile();\n */\n\nvar Whammy = (function() {\n    // a more abstract-ish API\n\n    function WhammyVideo(duration, quality) {\n        this.frames = [];\n        if (!duration) {\n            duration = 1;\n        }\n        this.duration = 1000 / duration;\n        this.quality = quality || 0.8;\n    }\n\n    /**\n     * Pass Canvas or Context or image/webp(string) to {@link Whammy} encoder.\n     * @method\n     * @memberof Whammy\n     * @example\n     * recorder = new Whammy().Video(0.8, 100);\n     * recorder.add(canvas || context || 'image/webp');\n     * @param {string} frame - Canvas || Context || image/webp\n     * @param {number} duration - Stick a duration (in milliseconds)\n     */\n    WhammyVideo.prototype.add = function(frame, duration) {\n        if ('canvas' in frame) { //CanvasRenderingContext2D\n            frame = frame.canvas;\n        }\n\n        if ('toDataURL' in frame) {\n            frame = frame.toDataURL('image/webp', this.quality);\n        }\n\n        if (!(/^data:image\\/webp;base64,/ig).test(frame)) {\n            throw 'Input must be formatted properly as a base64 encoded DataURI of type image/webp';\n        }\n        this.frames.push({\n            image: frame,\n            duration: duration || this.duration\n        });\n    };\n\n    function processInWebWorker(_function) {\n        var blob = URL.createObjectURL(new Blob([_function.toString(),\n            'this.onmessage =  function (e) {' + _function.name + '(e.data);}'\n        ], {\n            type: 'application/javascript'\n        }));\n\n        var worker = new Worker(blob);\n        URL.revokeObjectURL(blob);\n        return worker;\n    }\n\n    function whammyInWebWorker(frames) {\n        function ArrayToWebM(frames) {\n            var info = checkFrames(frames);\n            if (!info) {\n                return [];\n            }\n\n            var clusterMaxDuration = 30000;\n\n            var EBML = [{\n                'id': 0x1a45dfa3, // EBML\n                'data': [{\n                    'data': 1,\n                    'id': 0x4286 // EBMLVersion\n                }, {\n                    'data': 1,\n                    'id': 0x42f7 // EBMLReadVersion\n                }, {\n                    'data': 4,\n                    'id': 0x42f2 // EBMLMaxIDLength\n                }, {\n                    'data': 8,\n                    'id': 0x42f3 // EBMLMaxSizeLength\n                }, {\n                    'data': 'webm',\n                    'id': 0x4282 // DocType\n                }, {\n                    'data': 2,\n                    'id': 0x4287 // DocTypeVersion\n                }, {\n                    'data': 2,\n                    'id': 0x4285 // DocTypeReadVersion\n                }]\n            }, {\n                'id': 0x18538067, // Segment\n                'data': [{\n                    'id': 0x1549a966, // Info\n                    'data': [{\n                        'data': 1e6, //do things in millisecs (num of nanosecs for duration scale)\n                        'id': 0x2ad7b1 // TimecodeScale\n                    }, {\n                        'data': 'whammy',\n                        'id': 0x4d80 // MuxingApp\n                    }, {\n                        'data': 'whammy',\n                        'id': 0x5741 // WritingApp\n                    }, {\n                        'data': doubleToString(info.duration),\n                        'id': 0x4489 // Duration\n                    }]\n                }, {\n                    'id': 0x1654ae6b, // Tracks\n                    'data': [{\n                        'id': 0xae, // TrackEntry\n                        'data': [{\n                            'data': 1,\n                            'id': 0xd7 // TrackNumber\n                        }, {\n                            'data': 1,\n                            'id': 0x73c5 // TrackUID\n                        }, {\n                            'data': 0,\n                            'id': 0x9c // FlagLacing\n                        }, {\n                            'data': 'und',\n                            'id': 0x22b59c // Language\n                        }, {\n                            'data': 'V_VP8',\n                            'id': 0x86 // CodecID\n                        }, {\n                            'data': 'VP8',\n                            'id': 0x258688 // CodecName\n                        }, {\n                            'data': 1,\n                            'id': 0x83 // TrackType\n                        }, {\n                            'id': 0xe0, // Video\n                            'data': [{\n                                'data': info.width,\n                                'id': 0xb0 // PixelWidth\n                            }, {\n                                'data': info.height,\n                                'id': 0xba // PixelHeight\n                            }]\n                        }]\n                    }]\n                }]\n            }];\n\n            //Generate clusters (max duration)\n            var frameNumber = 0;\n            var clusterTimecode = 0;\n            while (frameNumber < frames.length) {\n\n                var clusterFrames = [];\n                var clusterDuration = 0;\n                do {\n                    clusterFrames.push(frames[frameNumber]);\n                    clusterDuration += frames[frameNumber].duration;\n                    frameNumber++;\n                } while (frameNumber < frames.length && clusterDuration < clusterMaxDuration);\n\n                var clusterCounter = 0;\n                var cluster = {\n                    'id': 0x1f43b675, // Cluster\n                    'data': getClusterData(clusterTimecode, clusterCounter, clusterFrames)\n                }; //Add cluster to segment\n                EBML[1].data.push(cluster);\n                clusterTimecode += clusterDuration;\n            }\n\n            return generateEBML(EBML);\n        }\n\n        function getClusterData(clusterTimecode, clusterCounter, clusterFrames) {\n            return [{\n                'data': clusterTimecode,\n                'id': 0xe7 // Timecode\n            }].concat(clusterFrames.map(function(webp) {\n                var block = makeSimpleBlock({\n                    discardable: 0,\n                    frame: webp.data.slice(4),\n                    invisible: 0,\n                    keyframe: 1,\n                    lacing: 0,\n                    trackNum: 1,\n                    timecode: Math.round(clusterCounter)\n                });\n                clusterCounter += webp.duration;\n                return {\n                    data: block,\n                    id: 0xa3\n                };\n            }));\n        }\n\n        // sums the lengths of all the frames and gets the duration\n\n        function checkFrames(frames) {\n            if (!frames[0]) {\n                postMessage({\n                    error: 'Something went wrong. Maybe WebP format is not supported in the current browser.'\n                });\n                return;\n            }\n\n            var width = frames[0].width,\n                height = frames[0].height,\n                duration = frames[0].duration;\n\n            for (var i = 1; i < frames.length; i++) {\n                duration += frames[i].duration;\n            }\n            return {\n                duration: duration,\n                width: width,\n                height: height\n            };\n        }\n\n        function numToBuffer(num) {\n            var parts = [];\n            while (num > 0) {\n                parts.push(num & 0xff);\n                num = num >> 8;\n            }\n            return new Uint8Array(parts.reverse());\n        }\n\n        function strToBuffer(str) {\n            return new Uint8Array(str.split('').map(function(e) {\n                return e.charCodeAt(0);\n            }));\n        }\n\n        function bitsToBuffer(bits) {\n            var data = [];\n            var pad = (bits.length % 8) ? (new Array(1 + 8 - (bits.length % 8))).join('0') : '';\n            bits = pad + bits;\n            for (var i = 0; i < bits.length; i += 8) {\n                data.push(parseInt(bits.substr(i, 8), 2));\n            }\n            return new Uint8Array(data);\n        }\n\n        function generateEBML(json) {\n            var ebml = [];\n            for (var i = 0; i < json.length; i++) {\n                var data = json[i].data;\n\n                if (typeof data === 'object') {\n                    data = generateEBML(data);\n                }\n\n                if (typeof data === 'number') {\n                    data = bitsToBuffer(data.toString(2));\n                }\n\n                if (typeof data === 'string') {\n                    data = strToBuffer(data);\n                }\n\n                var len = data.size || data.byteLength || data.length;\n                var zeroes = Math.ceil(Math.ceil(Math.log(len) / Math.log(2)) / 8);\n                var sizeToString = len.toString(2);\n                var padded = (new Array((zeroes * 7 + 7 + 1) - sizeToString.length)).join('0') + sizeToString;\n                var size = (new Array(zeroes)).join('0') + '1' + padded;\n\n                ebml.push(numToBuffer(json[i].id));\n                ebml.push(bitsToBuffer(size));\n                ebml.push(data);\n            }\n\n            return new Blob(ebml, {\n                type: 'video/webm'\n            });\n        }\n\n        function toBinStrOld(bits) {\n            var data = '';\n            var pad = (bits.length % 8) ? (new Array(1 + 8 - (bits.length % 8))).join('0') : '';\n            bits = pad + bits;\n            for (var i = 0; i < bits.length; i += 8) {\n                data += String.fromCharCode(parseInt(bits.substr(i, 8), 2));\n            }\n            return data;\n        }\n\n        function makeSimpleBlock(data) {\n            var flags = 0;\n\n            if (data.keyframe) {\n                flags |= 128;\n            }\n\n            if (data.invisible) {\n                flags |= 8;\n            }\n\n            if (data.lacing) {\n                flags |= (data.lacing << 1);\n            }\n\n            if (data.discardable) {\n                flags |= 1;\n            }\n\n            if (data.trackNum > 127) {\n                throw 'TrackNumber > 127 not supported';\n            }\n\n            var out = [data.trackNum | 0x80, data.timecode >> 8, data.timecode & 0xff, flags].map(function(e) {\n                return String.fromCharCode(e);\n            }).join('') + data.frame;\n\n            return out;\n        }\n\n        function parseWebP(riff) {\n            var VP8 = riff.RIFF[0].WEBP[0];\n\n            var frameStart = VP8.indexOf('\\x9d\\x01\\x2a'); // A VP8 keyframe starts with the 0x9d012a header\n            for (var i = 0, c = []; i < 4; i++) {\n                c[i] = VP8.charCodeAt(frameStart + 3 + i);\n            }\n\n            var width, height, tmp;\n\n            //the code below is literally copied verbatim from the bitstream spec\n            tmp = (c[1] << 8) | c[0];\n            width = tmp & 0x3FFF;\n            tmp = (c[3] << 8) | c[2];\n            height = tmp & 0x3FFF;\n            return {\n                width: width,\n                height: height,\n                data: VP8,\n                riff: riff\n            };\n        }\n\n        function getStrLength(string, offset) {\n            return parseInt(string.substr(offset + 4, 4).split('').map(function(i) {\n                var unpadded = i.charCodeAt(0).toString(2);\n                return (new Array(8 - unpadded.length + 1)).join('0') + unpadded;\n            }).join(''), 2);\n        }\n\n        function parseRIFF(string) {\n            var offset = 0;\n            var chunks = {};\n\n            while (offset < string.length) {\n                var id = string.substr(offset, 4);\n                var len = getStrLength(string, offset);\n                var data = string.substr(offset + 4 + 4, len);\n                offset += 4 + 4 + len;\n                chunks[id] = chunks[id] || [];\n\n                if (id === 'RIFF' || id === 'LIST') {\n                    chunks[id].push(parseRIFF(data));\n                } else {\n                    chunks[id].push(data);\n                }\n            }\n            return chunks;\n        }\n\n        function doubleToString(num) {\n            return [].slice.call(\n                new Uint8Array((new Float64Array([num])).buffer), 0).map(function(e) {\n                return String.fromCharCode(e);\n            }).reverse().join('');\n        }\n\n        var webm = new ArrayToWebM(frames.map(function(frame) {\n            var webp = parseWebP(parseRIFF(atob(frame.image.slice(23))));\n            webp.duration = frame.duration;\n            return webp;\n        }));\n\n        postMessage(webm);\n    }\n\n    /**\n     * Encodes frames in WebM container. It uses WebWorkinvoke to invoke 'ArrayToWebM' method.\n     * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\n     * @method\n     * @memberof Whammy\n     * @example\n     * recorder = new Whammy().Video(0.8, 100);\n     * recorder.compile(function(blob) {\n     *    // blob.size - blob.type\n     * });\n     */\n    WhammyVideo.prototype.compile = function(callback) {\n        var webWorker = processInWebWorker(whammyInWebWorker);\n\n        webWorker.onmessage = function(event) {\n            if (event.data.error) {\n                console.error(event.data.error);\n                return;\n            }\n            callback(event.data);\n        };\n\n        webWorker.postMessage(this.frames);\n    };\n\n    return {\n        /**\n         * A more abstract-ish API.\n         * @method\n         * @memberof Whammy\n         * @example\n         * recorder = new Whammy().Video(0.8, 100);\n         * @param {?number} speed - 0.8\n         * @param {?number} quality - 100\n         */\n        Video: WhammyVideo\n    };\n})();\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.Whammy = Whammy;\n}\n\n// Last time updated at Nov 18, 2014, 08:32:23\n\n// Latest file can be found here: https://cdn.webrtc-experiment.com/ConcatenateBlobs.js\n\n// Muaz Khan    - www.MuazKhan.com\n// MIT License  - www.WebRTC-Experiment.com/licence\n// Source Code  - https://github.com/muaz-khan/ConcatenateBlobs\n// Demo         - https://www.WebRTC-Experiment.com/ConcatenateBlobs/\n\n// ___________________\n// ConcatenateBlobs.js\n\n// Simply pass array of blobs.\n// This javascript library will concatenate all blobs in single \"Blob\" object.\n\n(function() {\n    window.ConcatenateBlobs = function(blobs, type, callback) {\n        var buffers = [];\n\n        var index = 0;\n\n        function readAsArrayBuffer() {\n            if (!blobs[index]) {\n                return concatenateBuffers();\n            }\n            var reader = new FileReader();\n            reader.onload = function(event) {\n                buffers.push(event.target.result);\n                index++;\n                readAsArrayBuffer();\n            };\n            reader.readAsArrayBuffer(blobs[index]);\n        }\n\n        readAsArrayBuffer();\n\n        function concatenateBuffers() {\n            var byteLength = 0;\n            buffers.forEach(function(buffer) {\n                byteLength += buffer.byteLength;\n            });\n\n            var tmp = new Uint16Array(byteLength);\n            var lastOffset = 0;\n            buffers.forEach(function(buffer) {\n                // BYTES_PER_ELEMENT == 2 for Uint16Array\n                var reusableByteLength = buffer.byteLength;\n                if (reusableByteLength % 2 != 0) {\n                    buffer = buffer.slice(0, reusableByteLength - 1)\n                }\n                tmp.set(new Uint16Array(buffer), lastOffset);\n                lastOffset += reusableByteLength;\n            });\n\n            var blob = new Blob([tmp.buffer], {\n                type: type\n            });\n\n            callback(blob);\n        }\n    };\n})();\n\n// https://github.com/streamproc/MediaStreamRecorder/issues/42\nif (true /* && !!module.exports*/ ) {\n    module.exports = MediaStreamRecorder;\n}\n\nif (true) {\n    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function() {\n        return MediaStreamRecorder;\n    }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/msr/MediaStreamRecorder.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n\n\n//# sourceURL=webpack:///(webpack)/buildin/global.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/*! no exports provided */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var msr__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! msr */ \"./node_modules/msr/MediaStreamRecorder.js\");\n/* harmony import */ var msr__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(msr__WEBPACK_IMPORTED_MODULE_0__);\n\n\nconst METRONOME_URL = \"./dist/metronome_60bpm_5s_divided.wav\";\nconst RECORDING_DURATION = 5000; // 5s\nlet mediaRecorder;\nlet recordButton;\nlet downloadPart;\n\nnavigator.getUserMedia =\n  navigator.getUserMedia ||\n  navigator.webkitGetUserMedia ||\n  navigator.mozGetUserMedia;\n\nconst setUp = (stream) => {\n    mediaRecorder = new msr__WEBPACK_IMPORTED_MODULE_0___default.a(stream);\n    mediaRecorder.mimeType = 'audio/wav';\n};\n\nconst onMicrophoneAccessError = () => {\n    alert(\"Can't record audio on your browser\");\n};\n\n\n// Playing metronome track\nwindow.AudioContext = window.AudioContext||window.webkitAudioContext;\nlet context = new AudioContext();\nlet metronomeBuffer;\nconst loadMetronomeTrack = () => {\n    let request = new XMLHttpRequest();\n    request.open('get', METRONOME_URL, true);\n    request.responseType = \"arraybuffer\";\n    request.onload = () => {\n        context.decodeAudioData(request.response, (buffer) => {\n            metronomeBuffer = buffer;\n        });\n    };\n    request.send();\n};\n\nconst playMetronome = () => {\n    let source = context.createBufferSource();\n    source.buffer = metronomeBuffer;\n    source.connect(context.destination);\n    source.start(0);\n};\n// End playing metronome track\n\n\n\nconst constraints = { audio: true };\n\nconst setUpRecorder = () => {\n    navigator.mediaDevices\n        .getUserMedia(constraints)\n        .then(setUp)\n        .catch(onMicrophoneAccessError)\n};\n\nconst stopRecorder = () => mediaRecorder && mediaRecorder.stop();\n\nconst processRecording = (blob, resolve) => {\n    stopRecorder();\n    let blobURL = URL.createObjectURL(blob);\n    downloadPart.innerHTML = \"<a href='\" + blobURL + \"' download='audio.wav'>Download audio</a>\";\n    if(resolve) {\n        resolve();\n    }\n};\n\nconst startRecording = () => {\n    return new Promise((resolve, reject) => {\n        if(mediaRecorder) {\n            mediaRecorder.stop();\n            mediaRecorder.ondataavailable = blob => {\n                processRecording(blob, resolve);\n            };\n            mediaRecorder.start(RECORDING_DURATION*2);\n            playMetronome();\n            setInterval(() => {\n                stopRecorder();\n            }, RECORDING_DURATION);\n        }\n        else {\n            reject();\n        }\n    });4\n};\n\nconst setupDOM = () => {\n    recordButton = document.getElementById(\"record-button\");\n    downloadPart = document.getElementById(\"download-part\")\n};\n\nconst addEventListeners = () => {\n    recordButton.addEventListener('click', (e) => {\n        recordButton.setAttribute(\"disabled\", \"\");\n        startRecording().then(() => {\n            recordButton.removeAttribute(\"disabled\");\n        });\n    });\n};\n\n\nloadMetronomeTrack();\nsetUpRecorder();\nsetupDOM();\naddEventListeners();\n\n//# sourceURL=webpack:///./src/index.js?");

/***/ })

/******/ });